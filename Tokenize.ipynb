{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "903c5057-3632-4d8b-870f-85cbbf70b2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185200\n",
      "1350\n",
      "       DocID           QueryID  \\\n",
      "0  Brilliant   Brilliant _26_0   \n",
      "1  Brilliant   Brilliant _26_1   \n",
      "2  Brilliant  Brilliant _26_10   \n",
      "3  Brilliant  Brilliant _26_11   \n",
      "4  Brilliant  Brilliant _26_12   \n",
      "\n",
      "                                               Query  \\\n",
      "0  Brilliant, what kind of information do you col...   \n",
      "1  Brilliant, who do you share the information with?   \n",
      "2               Brilliant, what data do you collect?   \n",
      "3           Brilliant, how long do you keep my data?   \n",
      "4     Brilliant, do you sell my data to 3rd parties?   \n",
      "\n",
      "                                             Segment  \n",
      "0  Brilliant Worldwide, Inc. (\"Brilliant\") knows ...  \n",
      "1  Brilliant Worldwide, Inc. (\"Brilliant\") knows ...  \n",
      "2  Brilliant Worldwide, Inc. (\"Brilliant\") knows ...  \n",
      "3  Brilliant Worldwide, Inc. (\"Brilliant\") knows ...  \n",
      "4  Brilliant Worldwide, Inc. (\"Brilliant\") knows ...  \n",
      "       question_tokens  answer_tokens\n",
      "count      1350.000000    1350.000000\n",
      "mean         12.297778    3671.481481\n",
      "std           3.310282    2538.161569\n",
      "min           6.000000     205.000000\n",
      "25%          10.000000    1958.000000\n",
      "50%          12.000000    3245.000000\n",
      "75%          14.000000    4652.000000\n",
      "max          30.000000   10944.000000\n",
      "Tokenized dataset saved.\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "csv_file1 =  \"PrivacyQA_EMNLP-master/data/policy_train_data.csv\"\n",
    "csv_file2 =  \"PrivacyQA_EMNLP-master/data/policy_test_data.csv\"\n",
    "df1 = pd.read_csv(csv_file1, delimiter=\"\\t\")\n",
    "df2 = pd.read_csv(csv_file1, delimiter=\"\\t\")\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")  # Change encoder if needed\n",
    "\n",
    "# Columns to tokenize\n",
    "columns_to_tokenize = [\"Query\", \"Segment\"]\n",
    "\n",
    "#Merge response segments of PrivacyQA together\n",
    "merged_df = df1.groupby([\"DocID\", \"QueryID\", \"Query\"], as_index=False).agg({\"Segment\": \" \".join})\n",
    "\n",
    "\n",
    "# Append DocID to Query\n",
    "merged_df[\"DocID\"] = merged_df[\"DocID\"].str.split().str[0]\n",
    "merged_df[\"Query\"] = merged_df[\"DocID\"] + \", \" + merged_df[\"Query\"]\n",
    "\n",
    "print(len(df1))\n",
    "print(len(merged_df))\n",
    "print(merged_df.head())\n",
    "\n",
    "#Just uploading training data for now\n",
    "#OpenAI format\n",
    "output1 = []\n",
    "for _, row in merged_df.iterrows():\n",
    "    output1.append({\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": row[\"Query\"]},\n",
    "            {\"role\": \"assistant\", \"content\": row[\"Segment\"]}\n",
    "        ]\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "# Save as JSONL\n",
    "with open(\"privacyqa_tune.jsonl\", \"w\") as f:\n",
    "    for entry in output1:\n",
    "        f.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")  # Use appropriate encoding for your model\n",
    "\n",
    "def count_tokens(text):\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "# Check average token count\n",
    "merged_df[\"question_tokens\"] = merged_df[\"Query\"].apply(count_tokens)\n",
    "merged_df[\"answer_tokens\"] = merged_df[\"Segment\"].apply(count_tokens)\n",
    "\n",
    "\n",
    "print(merged_df[[\"question_tokens\", \"answer_tokens\"]].describe())\n",
    "\n",
    "print(f\"Tokenized dataset saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4345cde-b67c-4591-9b66-b5d7d71a9fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded successfully! File ID: file-3G9BEGqBXHDdAnNfC9trUf\n"
     ]
    }
   ],
   "source": [
    "# Upload JSON to OpenAI\n",
    "from openai import OpenAI\n",
    "    \n",
    "client = OpenAI(api_key=\"\")\n",
    "\n",
    "try:\n",
    "    with open(\"med_qa_tune2000.jsonl\", \"rb\") as file:\n",
    "        response = client.files.create(\n",
    "            file=file,\n",
    "            purpose=\"fine-tune\"\n",
    "        )\n",
    "    file_id = response.id\n",
    "    print(f\"File uploaded successfully! File ID: {file_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf059ab2-aab7-4585-bfba-1c10a49650f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples: 2000\n",
      "First example:\n",
      "{'role': 'system', 'content': 'You are a helpful medical assistant.'}\n",
      "{'role': 'user', 'content': 'What is (are) Adult Acute Lymphoblastic Leukemia ?'}\n",
      "{'role': 'assistant', 'content': 'Key Points\\n                    - Adult acute lymphoblastic leukemia (ALL) is a type of cancer in which the bone marrow makes too many lymphocytes (a type of white blood cell).    - Leukemia may affect red blood cells, white blood cells, and platelets.    - Previous chemotherapy and exposure to radiation may increase the risk of developing ALL.    - Signs and symptoms of adult ALL include fever, feeling tired, and easy bruising or bleeding.     - Tests that examine the blood and bone marrow are used to detect (find) and diagnose adult ALL.    - Certain factors affect prognosis (chance of recovery) and treatment options.\\n                \\n                \\n                    Adult acute lymphoblastic leukemia (ALL) is a type of cancer in which the bone marrow makes too many lymphocytes (a type of white blood cell).\\n                    Adult acute lymphoblastic leukemia (ALL; also called acute lymphocytic leukemia) is a cancer of the blood and bone marrow. This type of cancer usually gets worse quickly if it is not treated.\\n                \\n                \\n                    Leukemia may affect red blood cells, white blood cells, and platelets.\\n                    Normally, the bone marrow makes blood stem cells (immature cells) that become mature blood cells over time. A blood stem cell may become a myeloid stem cell or a lymphoid stem cell.   A myeloid stem cell becomes one of three types of mature blood cells:          -  Red blood cells that carry oxygen and other substances to all tissues of the body.    -  Platelets that form blood clots to stop bleeding.    -  Granulocytes (white blood cells) that fight infection and disease.         A lymphoid stem cell becomes a lymphoblast cell and then one of three types of lymphocytes (white blood cells):         -  B lymphocytes that make antibodies to help fight infection.    -  T lymphocytes that help B lymphocytes make the antibodies that help fight infection.    -  Natural killer cells that attack cancer cells and viruses.         In ALL, too many stem cells become lymphoblasts, B lymphocytes, or T lymphocytes. These cells are also called leukemia cells. These leukemia cells are not able to fight infection very well. Also, as the number of leukemia cells increases in the blood and bone marrow, there is less room for healthy white blood cells, red blood cells, and platelets. This may cause infection, anemia, and easy bleeding. The cancer can also spread to the central nervous system (brain and spinal cord).     This summary is about adult acute lymphoblastic leukemia. See the following PDQ summaries for information about other types of leukemia:          -  Childhood Acute Lymphoblastic Leukemia Treatment.    -  Adult Acute Myeloid Leukemia Treatment.    -  Childhood Acute Myeloid Leukemia/Other Myeloid Malignancies Treatment.    -  Chronic Lymphocytic Leukemia Treatment.    -  Chronic Myelogenous Leukemia Treatment.    -  Hairy Cell Leukemia Treatment.'}\n"
     ]
    }
   ],
   "source": [
    "#Open AI Data preparation validation\n",
    "import json\n",
    "import tiktoken # for token counting\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "data_path = \"med_qa_tune2000.jsonl\"\n",
    "\n",
    "# Load the dataset\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Initial dataset stats\n",
    "print(\"Num examples:\", len(dataset))\n",
    "print(\"First example:\")\n",
    "for message in dataset[0][\"messages\"]:\n",
    "    print(message)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1632373c-1ded-439c-b106-923423812861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "#Error checks\n",
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "        \n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "        \n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "        \n",
    "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "        \n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "            \n",
    "        content = message.get(\"content\", None)\n",
    "        function_call = message.get(\"function_call\", None)\n",
    "        \n",
    "        if (not content and not function_call) or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "    \n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d89bea47-5529-4949-bb5f-1aaa0c852179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 36, 5715\n",
      "mean / median: 384.9615, 231.0\n",
      "p5 / p95: 105.0, 663.1000000000001\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 7, 5681\n",
      "mean / median: 350.598, 198.5\n",
      "p5 / p95: 72.0, 625.1000000000001\n",
      "\n",
      "0 examples may be over the 16,385 token limit, they will be truncated during fine-tuning\n",
      "Dataset has ~769923 tokens that will be charged for during training\n",
      "By default, you'll train for 3 epochs on this dataset\n",
      "By default, you'll be charged for ~2309769 tokens\n"
     ]
    }
   ],
   "source": [
    "### Cost Estimate ###\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# not exact!\n",
    "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
    "    \n",
    "# Warnings and tokens counts\n",
    "n_missing_system = 0\n",
    "n_missing_user = 0\n",
    "n_messages = []\n",
    "convo_lens = []\n",
    "assistant_message_lens = []\n",
    "\n",
    "for ex in dataset:\n",
    "    messages = ex[\"messages\"]\n",
    "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "        n_missing_system += 1\n",
    "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "        n_missing_user += 1\n",
    "    n_messages.append(len(messages))\n",
    "    convo_lens.append(num_tokens_from_messages(messages))\n",
    "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "    \n",
    "print(\"Num examples missing system message:\", n_missing_system)\n",
    "print(\"Num examples missing user message:\", n_missing_user)\n",
    "print_distribution(n_messages, \"num_messages_per_example\")\n",
    "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "n_too_long = sum(l > 16385 for l in convo_lens)\n",
    "print(f\"\\n{n_too_long} examples may be over the 16,385 token limit, they will be truncated during fine-tuning\")\n",
    "\n",
    "# Pricing and default n_epochs estimate\n",
    "MAX_TOKENS_PER_EXAMPLE = 16385\n",
    "\n",
    "TARGET_EPOCHS = 3\n",
    "MIN_TARGET_EXAMPLES = 100\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "MIN_DEFAULT_EPOCHS = 1\n",
    "MAX_DEFAULT_EPOCHS = 25\n",
    "\n",
    "n_epochs = TARGET_EPOCHS\n",
    "n_train_examples = len(dataset)\n",
    "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eee680b-1c94-4068-b144-8b55b7c6edf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
